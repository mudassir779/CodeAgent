"""Mock LLM provider for testing without API keys."""

from __future__ import annotations
import json
import random
from typing import Any, AsyncIterator

from .base import BaseLLMProvider
from .types import LLMResponse, Message, ToolCall


# Patterns: if user message contains keyword, use a tool
TOOL_PATTERNS = {
    "read": {
        "tool": "file_read",
        "arg_key": "path",
        "extract": "file",
        "default_args": {"path": "pyproject.toml"},
        "followup": "Here's the file content above. Let me know if you need anything else!",
    },
    "write": {
        "tool": "file_write",
        "default_args": {
            "path": "hello.py",
            "content": '#!/usr/bin/env python3\n"""Generated by CodeAgent."""\n\nprint("Hello World!")\n',
        },
        "followup": "I've created the file for you!",
    },
    "create": {
        "tool": "file_write",
        "default_args": {
            "path": "hello.py",
            "content": '#!/usr/bin/env python3\n"""Generated by CodeAgent."""\n\nprint("Hello World!")\n',
        },
        "followup": "File created successfully!",
    },
    "list": {
        "tool": "directory_list",
        "default_args": {"path": "."},
        "followup": "Here's the directory listing above.",
    },
    "search": {
        "tool": "code_search",
        "default_args": {"pattern": "def execute", "path": "codeagent/tools"},
        "followup": "Found the matches above. Want me to look at any of these files?",
    },
    "git": {
        "tool": "git_ops",
        "default_args": {"operation": "status"},
        "followup": "Here's the git status. What would you like to do next?",
    },
    "status": {
        "tool": "git_ops",
        "default_args": {"operation": "status"},
        "followup": "Git status shown above.",
    },
    "terminal": {
        "tool": "terminal",
        "default_args": {"command": "echo 'Hello from CodeAgent!'"},
        "followup": "Command executed successfully!",
    },
    "run": {
        "tool": "terminal",
        "default_args": {"command": "echo 'Hello from CodeAgent!'"},
        "followup": "Done! Here's the output above.",
    },
}

GENERIC_RESPONSES = [
    "I'm CodeAgent running in **demo mode** (no API key). I can simulate tool usage!\n\nTry asking me to:\n- **read** a file\n- **create** a file\n- **list** directory contents\n- **search** for code\n- **git** status\n- **run** a command",
    "I'm in demo mode right now. Try asking me to read, write, search, or run commands!",
    "Demo mode active! Ask me to interact with files, search code, or run git commands.",
]


class MockProvider(BaseLLMProvider):
    """Simulates LLM responses for testing without API keys."""

    def __init__(self) -> None:
        self._call_count = 0

    def chat(
        self,
        messages: list[Message],
        tools: list[dict[str, Any]] | None = None,
        system: str = "",
    ) -> LLMResponse:
        self._call_count += 1

        # Check if last message was a tool result â€” return followup text
        if messages and messages[-1].role == "tool":
            for msg in reversed(messages):
                if msg.role == "assistant" and msg.tool_calls:
                    tool_name = msg.tool_calls[0].name
                    for pattern_info in TOOL_PATTERNS.values():
                        if pattern_info["tool"] == tool_name:
                            return LLMResponse(
                                content=pattern_info["followup"],
                                stop_reason="end_turn",
                            )
                    break
            return LLMResponse(content="Done! What's next?", stop_reason="end_turn")

        # Get latest user message
        user_msg = ""
        for msg in reversed(messages):
            if msg.role == "user":
                user_msg = msg.content.lower()
                break

        # Match user input to a tool pattern
        for keyword, pattern_info in TOOL_PATTERNS.items():
            if keyword in user_msg:
                tool_call = ToolCall(
                    id=f"mock_{self._call_count}",
                    name=pattern_info["tool"],
                    arguments=dict(pattern_info["default_args"]),
                )
                return LLMResponse(
                    content="",
                    tool_calls=[tool_call],
                    stop_reason="tool_use",
                )

        # Generic response
        return LLMResponse(
            content=random.choice(GENERIC_RESPONSES),
            stop_reason="end_turn",
        )

    async def stream_chat(
        self,
        messages: list[Message],
        tools: list[dict[str, Any]] | None = None,
        system: str = "",
    ) -> AsyncIterator[str]:
        response = self.chat(messages, tools, system)
        for word in response.content.split(" "):
            yield word + " "

    def get_model_name(self) -> str:
        return "Mock (Demo Mode - No API Key)"
